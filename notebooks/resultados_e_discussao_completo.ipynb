{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd585cea",
   "metadata": {},
   "source": [
    "## 1. Importar Bibliotecas e Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    average_precision_score,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix\n",
    ")\n",
    "import joblib\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuração de cores consistentes\n",
    "MODEL_COLORS = {\n",
    "    'MLP Centralizado': '#1f77b4',\n",
    "    'MLP Federado': '#ff7f0e',\n",
    "    'XGBoost Centralizado': '#2ca02c',\n",
    "    'XGBoost Federado (Bagging)': '#d62728',\n",
    "    'XGBoost Federado (Cyclic)': '#9467bd'\n",
    "}\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a1b98f",
   "metadata": {},
   "source": [
    "## 2. Definir Caminhos e Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d07a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caminhos base\n",
    "project_root = Path.cwd().parent\n",
    "centralized_dir = project_root / 'centralized_training' / 'models'\n",
    "flwr_mlp_dir = project_root / 'flwr-mlp' / 'models'\n",
    "flwr_xgb_dir = project_root / 'flwr-xgboost' / 'models'\n",
    "xai_dir = project_root / 'xAI'\n",
    "datasets_dir = project_root / 'datasets'\n",
    "\n",
    "# Verificar existência\n",
    "print(\"Verificando estrutura de diretórios...\")\n",
    "for path in [centralized_dir, flwr_mlp_dir, flwr_xgb_dir, xai_dir, datasets_dir]:\n",
    "    status = \"OK\" if path.exists() else \"AUSENTE\"\n",
    "    print(f\"  [{status}] {path.name}: {path}\")\n",
    "\n",
    "# Carregar índices de teste\n",
    "test_indices_df = pd.read_csv(datasets_dir / 'test_indices.csv')\n",
    "test_indices = test_indices_df['index'].values\n",
    "print(f\"\\n{len(test_indices)} amostras de teste carregadas\")\n",
    "print(f\"Colunas disponíveis: {list(test_indices_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cc933",
   "metadata": {},
   "source": [
    "## 1.1. Curvas de Aprendizado (Convergência)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar históricos de treinamento\n",
    "print(\"Carregando históricos de treinamento...\\n\")\n",
    "\n",
    "histories = {}\n",
    "\n",
    "# MLP Centralizado\n",
    "mlp_cent_path = centralized_dir / 'mlp' / 'training_history.csv'\n",
    "if mlp_cent_path.exists():\n",
    "    histories['MLP Centralizado'] = pd.read_csv(mlp_cent_path)\n",
    "    print(f\"[OK] MLP Centralizado: {len(histories['MLP Centralizado'])} épocas\")\n",
    "else:\n",
    "    print(f\"[AUSENTE] MLP Centralizado: NÃO ENCONTRADO\")\n",
    "\n",
    "# XGBoost Centralizado\n",
    "xgb_cent_path = centralized_dir / 'xgboost' / 'training_history.csv'\n",
    "if xgb_cent_path.exists():\n",
    "    histories['XGBoost Centralizado'] = pd.read_csv(xgb_cent_path)\n",
    "    print(f\"[OK] XGBoost Centralizado: {len(histories['XGBoost Centralizado'])} iterações\")\n",
    "else:\n",
    "    print(f\"[AUSENTE] XGBoost Centralizado: NÃO ENCONTRADO\")\n",
    "\n",
    "# MLP Federado\n",
    "mlp_fed_path = flwr_mlp_dir / 'training_history.csv'\n",
    "if mlp_fed_path.exists():\n",
    "    histories['MLP Federado'] = pd.read_csv(mlp_fed_path)\n",
    "    print(f\"[OK] MLP Federado: {len(histories['MLP Federado'])} rounds\")\n",
    "else:\n",
    "    print(f\"[AUSENTE] MLP Federado: NÃO ENCONTRADO\")\n",
    "\n",
    "print(f\"\\nTotal de modelos com histórico: {len(histories)}/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9399bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar curvas de aprendizado\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "fig.suptitle('Curvas de Aprendizado: Convergência dos Modelos', fontsize=16, fontweight='bold')\n",
    "\n",
    "# MLP Centralizado\n",
    "if 'MLP Centralizado' in histories:\n",
    "    df = histories['MLP Centralizado']\n",
    "    axes[0].plot(df['epoch'], df['val_aucpr'], 'o-', label='Val AUCPR', linewidth=2, markersize=4)\n",
    "    axes[0].plot(df['epoch'], df['val_auc'], 's-', label='Val AUC', linewidth=2, markersize=4, alpha=0.7)\n",
    "    axes[0].set_xlabel('Época', fontweight='bold')\n",
    "    axes[0].set_ylabel('Métrica', fontweight='bold')\n",
    "    axes[0].set_title('MLP Centralizado', fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    best_epoch = df['val_aucpr'].idxmax() + 1\n",
    "    axes[0].axvline(x=best_epoch, color='red', linestyle='--', alpha=0.5, label=f'Best: {best_epoch}')\n",
    "\n",
    "# XGBoost Centralizado\n",
    "if 'XGBoost Centralizado' in histories:\n",
    "    df = histories['XGBoost Centralizado']\n",
    "    axes[1].plot(df['iteration'], df['val_aucpr'], 'o-', label='Val AUCPR', linewidth=2, markersize=4)\n",
    "    axes[1].plot(df['iteration'], df['val_auc'], 's-', label='Val AUC', linewidth=2, markersize=4, alpha=0.7)\n",
    "    axes[1].set_xlabel('Iteração (Árvore)', fontweight='bold')\n",
    "    axes[1].set_ylabel('Métrica', fontweight='bold')\n",
    "    axes[1].set_title('XGBoost Centralizado', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    best_iter = df['val_aucpr'].idxmax() + 1\n",
    "    axes[1].axvline(x=best_iter, color='red', linestyle='--', alpha=0.5, label=f'Best: {best_iter}')\n",
    "\n",
    "# MLP Federado\n",
    "if 'MLP Federado' in histories:\n",
    "    df = histories['MLP Federado']\n",
    "    axes[2].plot(df['round'], df['val_aucpr'], 'o-', label='Val AUCPR', linewidth=2, markersize=4)\n",
    "    axes[2].plot(df['round'], df['val_auc'], 's-', label='Val AUC', linewidth=2, markersize=4, alpha=0.7)\n",
    "    axes[2].set_xlabel('Round', fontweight='bold')\n",
    "    axes[2].set_ylabel('Métrica', fontweight='bold')\n",
    "    axes[2].set_title('MLP Federado (FedAvg)', fontweight='bold')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    best_round = df['val_aucpr'].idxmax() + 1\n",
    "    axes[2].axvline(x=best_round, color='red', linestyle='--', alpha=0.5, label=f'Best: Round {best_round}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'notebooks' / 'fig1_curvas_aprendizado.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigura 1 salva: fig1_curvas_aprendizado.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46880107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise quantitativa de convergência\n",
    "print(\"=\"*80)\n",
    "print(\"ANÁLISE DE CONVERGÊNCIA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, df in histories.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    # Identificar coluna de iteração\n",
    "    iter_col = 'epoch' if 'epoch' in df.columns else ('round' if 'round' in df.columns else 'iteration')\n",
    "    \n",
    "    # Melhor performance\n",
    "    best_idx = df['val_aucpr'].idxmax()\n",
    "    best_iter = df.loc[best_idx, iter_col]\n",
    "    best_aucpr = df.loc[best_idx, 'val_aucpr']\n",
    "    \n",
    "    # Performance final\n",
    "    final_aucpr = df['val_aucpr'].iloc[-1]\n",
    "    \n",
    "    # Degradação\n",
    "    degradation = best_aucpr - final_aucpr\n",
    "    degradation_pct = (degradation / best_aucpr) * 100\n",
    "    \n",
    "    # Rounds/épocas de overfitting\n",
    "    overfit_iters = len(df) - (best_idx + 1)\n",
    "    overfit_pct = (overfit_iters / len(df)) * 100\n",
    "    \n",
    "    print(f\"  Melhor {iter_col}: {best_iter} (AUCPR: {best_aucpr:.6f})\")\n",
    "    print(f\"  Final {iter_col}: {len(df)} (AUCPR: {final_aucpr:.6f})\")\n",
    "    print(f\"  Degradação: {degradation:.6f} ({degradation_pct:.2f}%)\")\n",
    "    print(f\"  Iterações pós-best: {overfit_iters}/{len(df)} ({overfit_pct:.1f}%)\")\n",
    "    \n",
    "    if degradation > 0.01:\n",
    "        print(f\"  [ALERTA] Degradação significativa detectada\")\n",
    "    else:\n",
    "        print(f\"  [OK] Convergência estável\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130966b",
   "metadata": {},
   "source": [
    "## 1.2. Tabela de Métricas de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05181d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparando análise de métricas de classificação...\")\n",
    "print(\"\\n[INFO] Requer carregar modelos e fazer predições no conjunto de teste\")\n",
    "print(\"\\nEsta célula será completada na próxima etapa com:\")\n",
    "print(\"  - Acurácia\")\n",
    "print(\"  - Precisão, Recall, F1-Score\")\n",
    "print(\"  - AUC-ROC\")\n",
    "print(\"  - AUC-PR (métrica principal)\")\n",
    "print(\"  - Matthews Correlation Coefficient (MCC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e207ec",
   "metadata": {},
   "source": [
    "## 2.1. Comparação de Feature Importance (SHAP) + Correlação de Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar feature importance de todos os modelos\n",
    "print(\"Carregando SHAP Feature Importance...\\n\")\n",
    "\n",
    "shap_importance = {}\n",
    "\n",
    "# Caminhos para cada modelo\n",
    "shap_paths = {\n",
    "    'MLP Centralizado': xai_dir / 'shap_results_centralized' / 'mlp' / 'feature_importance_all.csv',\n",
    "    'MLP Federado': xai_dir / 'shap_results_federated' / 'mlp' / 'feature_importance_all.csv',\n",
    "    'XGBoost Centralizado': xai_dir / 'shap_results_centralized' / 'xgboost' / 'feature_importance_all.csv',\n",
    "    'XGBoost Federado (Bagging)': xai_dir / 'shap_results_federated' / 'xgboost' / 'bagging_strategy' / 'feature_importance_all.csv',\n",
    "    'XGBoost Federado (Cyclic)': xai_dir / 'shap_results_federated' / 'xgboost' / 'cyclic_strategy' / 'feature_importance_all.csv',\n",
    "}\n",
    "\n",
    "for model_name, path in shap_paths.items():\n",
    "    if path.exists():\n",
    "        shap_importance[model_name] = pd.read_csv(path)\n",
    "        print(f\"[OK] {model_name}: {len(shap_importance[model_name])} features\")\n",
    "    else:\n",
    "        print(f\"[AUSENTE] {model_name}: NÃO ENCONTRADO\")\n",
    "\n",
    "print(f\"\\nTotal de modelos carregados: {len(shap_importance)}/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar Feature Importance lado a lado\n",
    "n_models = len(shap_importance)\n",
    "fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 6))\n",
    "if n_models == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "fig.suptitle('Comparação de Feature Importance Global (SHAP)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for ax, (model_name, df) in zip(axes, shap_importance.items()):\n",
    "    # Pegar top 15 features\n",
    "    top_features = df.nlargest(15, 'Mean_Abs_SHAP')\n",
    "    \n",
    "    # Plotar barras horizontais\n",
    "    ax.barh(range(len(top_features)), top_features['Mean_Abs_SHAP'], \n",
    "            color=MODEL_COLORS.get(model_name, 'gray'), alpha=0.8)\n",
    "    ax.set_yticks(range(len(top_features)))\n",
    "    ax.set_yticklabels(top_features['Feature'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Mean |SHAP Value|', fontweight='bold')\n",
    "    ax.set_title(model_name, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'notebooks' / 'fig2_feature_importance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigura 2 salva: fig2_feature_importance_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular Correlação de Spearman entre todos os pares de modelos\n",
    "from itertools import combinations\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANÁLISE DE CORRELAÇÃO DE SPEARMAN (ρ)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nMedida de concordância entre rankings de feature importance\\n\")\n",
    "\n",
    "# Preparar dados para correlação\n",
    "model_names = list(shap_importance.keys())\n",
    "spearman_results = []\n",
    "\n",
    "for model1, model2 in combinations(model_names, 2):\n",
    "    df1 = shap_importance[model1].set_index('Feature')['Mean_Abs_SHAP']\n",
    "    df2 = shap_importance[model2].set_index('Feature')['Mean_Abs_SHAP']\n",
    "    \n",
    "    # Alinhar features (usar apenas features comuns)\n",
    "    common_features = df1.index.intersection(df2.index)\n",
    "    df1_aligned = df1[common_features]\n",
    "    df2_aligned = df2[common_features]\n",
    "    \n",
    "    # Calcular Spearman\n",
    "    rho, p_value = spearmanr(df1_aligned, df2_aligned)\n",
    "    \n",
    "    spearman_results.append({\n",
    "        'Modelo 1': model1,\n",
    "        'Modelo 2': model2,\n",
    "        'Spearman ρ': rho,\n",
    "        'p-value': p_value,\n",
    "        'Features Comuns': len(common_features)\n",
    "    })\n",
    "    \n",
    "    # Interpretar\n",
    "    if rho >= 0.9:\n",
    "        interpretation = \"[EXCELENTE] Concordância MUITO ALTA\"\n",
    "    elif rho >= 0.7:\n",
    "        interpretation = \"[BOM] Concordância ALTA\"\n",
    "    elif rho >= 0.5:\n",
    "        interpretation = \"[MODERADO] Concordância MODERADA\"\n",
    "    else:\n",
    "        interpretation = \"[BAIXO] Concordância BAIXA\"\n",
    "    \n",
    "    print(f\"{model1} vs {model2}:\")\n",
    "    print(f\"  ρ = {rho:.4f} (p < {p_value:.2e})\")\n",
    "    print(f\"  {interpretation}\\n\")\n",
    "\n",
    "# Criar DataFrame de resultados\n",
    "spearman_df = pd.DataFrame(spearman_results)\n",
    "\n",
    "# Salvar resultados\n",
    "spearman_df.to_csv(project_root / 'notebooks' / 'spearman_correlation_results.csv', index=False)\n",
    "print(\"\\nResultados salvos: spearman_correlation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar matriz de correlação de Spearman\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Criar matriz de correlação\n",
    "n_models = len(model_names)\n",
    "corr_matrix = np.eye(n_models)\n",
    "\n",
    "for i, model1 in enumerate(model_names):\n",
    "    for j, model2 in enumerate(model_names):\n",
    "        if i < j:\n",
    "            df1 = shap_importance[model1].set_index('Feature')['Mean_Abs_SHAP']\n",
    "            df2 = shap_importance[model2].set_index('Feature')['Mean_Abs_SHAP']\n",
    "            common_features = df1.index.intersection(df2.index)\n",
    "            rho, _ = spearmanr(df1[common_features], df2[common_features])\n",
    "            corr_matrix[i, j] = rho\n",
    "            corr_matrix[j, i] = rho\n",
    "\n",
    "# Plotar heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            xticklabels=[name.replace(' ', '\\n') for name in model_names],\n",
    "            yticklabels=model_names,\n",
    "            vmin=0, vmax=1, center=0.7,\n",
    "            cbar_kws={'label': 'Correlação de Spearman (ρ)'},\n",
    "            ax=ax)\n",
    "ax.set_title('Matriz de Correlação de Rankings (Feature Importance)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'notebooks' / 'fig3_spearman_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigura 3 salva: fig3_spearman_heatmap.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc-pytorch-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
